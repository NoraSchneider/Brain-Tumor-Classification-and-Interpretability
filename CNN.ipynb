{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1d40f075",
   "metadata": {},
   "source": [
    "# Task 3: Advanced CNN\n",
    "\n",
    "We implement and evaluate an additional CNN architecture which has less parameters and further uses dropout- and maxpool-layers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cdb254d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import numpy as np\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import accuracy_score, f1_score, plot_confusion_matrix, confusion_matrix, ConfusionMatrixDisplay\n",
    "\n",
    "import torch\n",
    "from torchvision import datasets, models, transforms\n",
    "import torch.nn as nn\n",
    "from torch.nn import functional as F\n",
    "from torch.nn import CrossEntropyLoss\n",
    "from torch.optim import Adam, SGD, RMSprop, lr_scheduler\n",
    "from torch.utils.data import TensorDataset, DataLoader, ConcatDataset\n",
    "\n",
    "import shap\n",
    "\n",
    "from data import get_img_dataset\n",
    "from project3Lib.transforms import EnhanceContrast\n",
    "import project3Lib.CNN as cnn\n",
    "from project3Lib.CNN import train_model, test, predict\n",
    "import project3Lib.utils as utils\n",
    "\n",
    "from masked_dataset import MaskedDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69c90e87",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# load data and transform data if augmentation == yes\n",
    "augmentation = input(\"Use augmentation? [yes/no]\").lower() == \"yes\"\n",
    "\n",
    "unique = input(\"Use unique images?[yes/no]\").lower() == \"yes\"\n",
    "input_path = \"data/unique_images\" if unique else \"data/images\"\n",
    "\n",
    "if augmentation:\n",
    "    transform = [EnhanceContrast(reduce_dim=False), transforms.Grayscale()]\n",
    "    train_dataset,val_dataset, test_dataset = get_img_dataset(transform, data_path=input_path, use_same_transforms = True)\n",
    "    transform = [EnhanceContrast(reduce_dim=False), transforms.Grayscale(), transforms.RandomRotation(70), transforms.RandomHorizontalFlip(), transforms.ColorJitter()]\n",
    "    train_dataset2,val_dataset2, _ = get_img_dataset(transform,data_path=input_path, use_same_transforms = True)\n",
    "    train_dataset = ConcatDataset([train_dataset,train_dataset2])\n",
    "    val_dataset = ConcatDataset([val_dataset,val_dataset2,val_dataset2])\n",
    "    model_file_path = \"AdvancedCNN_augmented_unique\" if unique else \"baselineCNN_augmented\"\n",
    "    \n",
    "else: \n",
    "    train_dataset, val_dataset, test_dataset = get_img_dataset(data_path=input_path)\n",
    "    \n",
    "    model_file_path = \"AdvancedCNN_unique\" if unique else \"baselineCNN\"\n",
    "    \n",
    "device = 'cuda:0' if torch.cuda.is_available() else 'cpu'\n",
    "print('Device state:', device)\n",
    "batch_size = 16\n",
    "trainloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "testloader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "validloader = DataLoader(val_dataset, batch_size=batch_size, shuffle=True)\n",
    "print(f\"Class sizes{np.unique([y for x,y in train_dataset], return_counts = True)}\")\n",
    "\n",
    "dataloaders = {\n",
    "    'train' : trainloader, \n",
    "    'validation': validloader\n",
    "}\n",
    "\n",
    "image_datasets = {\n",
    "    'train': train_dataset,\n",
    "    'validation': val_dataset\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62634d88",
   "metadata": {},
   "outputs": [],
   "source": [
    "total_trainable_params = sum(\n",
    "    p.numel() for p in cnn.CNN().parameters() if p.requires_grad)\n",
    "print(f'{total_trainable_params:,} training parameters.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65681c6f",
   "metadata": {},
   "source": [
    "# Model Implementation\n",
    "## Train classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "579c11d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 20\n",
    "accs = []\n",
    "f1s = []\n",
    "for i in range(n):\n",
    "    model = cnn.CNN()\n",
    "    criterion = CrossEntropyLoss()\n",
    "    optimizer = RMSprop(model.parameters(), lr=0.0001)\n",
    "    epochs = 50\n",
    "    model = train_model(model, criterion, optimizer, dataloaders, image_datasets, 3, num_epochs=epochs)\n",
    "    model.eval()\n",
    "    acc, f1 = test(model, test_dataset)\n",
    "    accs.append(acc)\n",
    "    f1s.append(f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1f294d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "a, f = test(model, test_dataset)\n",
    "print(f\"Accuracy mean: {np.mean(accs)} std: {np.std(accs)}\")\n",
    "print(f\"F1 mean: {np.mean(f1s)} std: {np.std(f1s)}\")\n",
    "print(f\"Score of saved model: acc = {a} and f1 = {f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbe5bc6b",
   "metadata": {},
   "source": [
    "```\n",
    "Accuracy mean: 0.74 std: 0.066332495807108\n",
    "F1 mean: 0.7591884057971013 std: 0.08237728074604544\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba1da527",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), f\"{model_file_path}.pt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44601dd8",
   "metadata": {},
   "source": [
    "## Evaluate Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7c8d8fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = cnn.CNN()\n",
    "model.load_state_dict(torch.load(f\"{model_file_path}.pt\"))\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ec785bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test = [i for i,j in test_dataset]\n",
    "y_test = [j for i,j in test_dataset]\n",
    "preds = []\n",
    "outs = []\n",
    "for t in x_test:\n",
    "    pred, out = predict(model, t)\n",
    "    preds.append(pred)\n",
    "    \n",
    "print(f\"Accuracy: {accuracy_score(preds,y_test)}\")\n",
    "print(f\"F1 score: {f1_score(preds,y_test)}\")\n",
    "\n",
    "cm=confusion_matrix(y_test,preds,normalize=\"true\")\n",
    "cmd = ConfusionMatrixDisplay(cm)\n",
    "cmd.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bab0339c",
   "metadata": {},
   "source": [
    "Performance scores\n",
    "\n",
    "```\n",
    "Accuracy: 0.85\n",
    "F1 score: 0.888888888888889\n",
    "```\n",
    "\n",
    "![](Plots/CM_CNN.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1fe8220",
   "metadata": {},
   "source": [
    "# Interpretability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3c38abf",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset_nomask = test_dataset\n",
    "transform = [transforms.Grayscale()]\n",
    "common_transform = [EnhanceContrast(reduce_dim=False)]\n",
    "_,_, test_dataset = get_img_dataset(transform = transform, \\\n",
    "                                    use_same_transforms=True, \\\n",
    "                                    common_transforms=common_transform, \\\n",
    "                                    data_path=input_path, \\\n",
    "                                    folder_type = MaskedDataset, \\\n",
    "                                    mask_folder=Path(\"data/masks\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d21ee5e8",
   "metadata": {},
   "source": [
    "\n",
    "## SHAP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d132d70",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Deep Explainer\n",
    "bg = [i for i,j in train_dataset]\n",
    "bg = torch.stack(bg)\n",
    "e = shap.DeepExplainer(model, bg)\n",
    "outs = []\n",
    "for i in bg:\n",
    "    pred, out = predict(model,i)\n",
    "    outs.append((out[0][0].item(), out[0][1].item()))\n",
    "print(f\"Mean values {np.mean([i for i,j in outs])}, {np.mean([j for i,j in outs])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7d477f2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "ious = []\n",
    "for i, (image,mask,target) in enumerate(test_dataset):\n",
    "    image = image.reshape((1,1,128,128))\n",
    "    pred, out = predict(model,image)\n",
    "    \n",
    "    shap_values = e.shap_values(image)\n",
    "    shap_numpy = [np.swapaxes(np.swapaxes(s, 1, -1), 1, 2) for s in shap_values]\n",
    "    test_numpy = np.swapaxes(np.swapaxes(image.cpu().numpy(), 1, -1), 1, 2)\n",
    "    print(f\"Image #{i}: True Class {target}, Prediction {pred}, Probabilities {out}\")\n",
    "    shap.image_plot(shap_numpy, test_numpy, labels = [\"SHAP for class 0\",\"SHAP for class 1\"])\n",
    "    \n",
    "    predicted_mask = np.copy(shap_values[1].reshape(128,128))\n",
    "    mask = mask.numpy().reshape((128,128))\n",
    "    pixels = int(np.sum(mask.flatten()))\n",
    "    iou = utils.evaluate_interpretability(predicted_mask, mask,pixels)\n",
    "    print(iou)\n",
    "    if target == 1:\n",
    "        ious.append(iou)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91b4fe6f",
   "metadata": {},
   "source": [
    "```\n",
    "The mean iou is 0.3190489056289843\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "104d263c",
   "metadata": {},
   "source": [
    "# Integrated Gradients with Captum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a2d50db",
   "metadata": {},
   "outputs": [],
   "source": [
    "ious = []\n",
    "plots = []\n",
    "for i, (image,mask,target) in enumerate(test_dataset):\n",
    "    data = (image,target)\n",
    "    if target == 1: \n",
    "        class_1, class_0 = utils.plot_grads(data,model, plot=False,grad_type= \"integ_grads\")\n",
    "    else:\n",
    "        class_0, class_1 = utils.plot_grads(data,model, plot=False,grad_type= \"integ_grads\")\n",
    "    predicted_mask = np.copy(class_1.cpu().detach().numpy().reshape(128,128))\n",
    "    mask = mask.numpy().reshape((128,128))\n",
    "    pixels = int(np.sum(mask.flatten()))\n",
    "    iou = utils.evaluate_interpretability(predicted_mask, mask,pixels)\n",
    "    if target == 1:\n",
    "        ious.append(iou)\n",
    "    if i == 0:\n",
    "        plots.append(predicted_mask)\n",
    "    if i == 1:\n",
    "        plots.append(predicted_mask)\n",
    "print(f\"The mean iou is {np.mean(ious)}\")\n",
    "for i, plot in enumerate(plots): \n",
    "    np.save(f\"Plots/AdvancedCNN_IntGrad_{i}\", plot)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8b42954",
   "metadata": {},
   "source": [
    "```\n",
    "The mean iou is 0.3106789354483127\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f627db9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "utils.plot_grads_dataloader(test_dataset_nomask, model, grad_type= \"integ_grads\" ,plot=True, save_name=\"cnn\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2903390",
   "metadata": {},
   "source": [
    "# GradCam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bb1fae3",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.model[4] # last conv layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f718fca",
   "metadata": {},
   "outputs": [],
   "source": [
    "ious = []\n",
    "plots = []\n",
    "for i, (image,mask, target) in enumerate(test_dataset):\n",
    "    data = (image,target)\n",
    "    \n",
    "    if target == 1: \n",
    "        class_1, class_0 = utils.plot_grads(data,model, layer_idx = 4,plot=False,grad_type= \"grad_cam\")\n",
    "    else:\n",
    "        class_0, class_1 = utils.plot_grads(data,model, layer_idx = 4,plot=False,grad_type= \"grad_cam\")\n",
    "    predicted_mask = np.copy(class_1.cpu().detach().numpy().reshape(128,128))\n",
    "    mask = mask.numpy().reshape((128,128))\n",
    "    pixels = int(np.sum(mask.flatten()))\n",
    "    iou = utils.evaluate_interpretability(predicted_mask, mask,pixels)\n",
    "    if target == 1:\n",
    "        ious.append(iou)\n",
    "    if i == 0:\n",
    "        np.save(f\"Plots/AdvancedCNN_GradCam_0\", predicted_mask)\n",
    "    if i == 1:\n",
    "        np.save(f\"Plots/AdvancedCNN_GradCam_1\", predicted_mask)\n",
    "print(f\"The mean iou is {np.mean(ious)}\")\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f7bb261",
   "metadata": {},
   "source": [
    "```\n",
    "The mean iou is 0.2718315831205122\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5319908",
   "metadata": {},
   "outputs": [],
   "source": [
    "utils.plot_grads_dataloader(test_dataset_og, model, grad_type= \"grad_cam\" ,plot=True,layer_idx=4, save_name=\"cnn\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db887894",
   "metadata": {},
   "source": [
    "## Appendix: Minimal adjusted CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b5d3d99",
   "metadata": {},
   "outputs": [],
   "source": [
    "total_trainable_params = sum(\n",
    "    p.numel() for p in SmallCNN().parameters() if p.requires_grad)\n",
    "print(f'{total_trainable_params:,} training parameters.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51cd287f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "\n",
    "class SmallCNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Conv2d(1, 32, kernel_size=3, stride=2, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(32, 32, kernel_size=3, stride=2, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "            nn.Dropout(p=0.2),\n",
    "            nn.Conv2d(32, 128, kernel_size=3, stride=2, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(128, 128, kernel_size=3, stride=2, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "            nn.Dropout(p=0.2),\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(512, 64),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.Dropout(p=0.2),\n",
    "            nn.Linear(64, 2),\n",
    "            nn.Softmax(dim=-1),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.model(x)\n",
    "\n",
    "    def training_step(self, batch):\n",
    "        images, labels = batch\n",
    "        # Get predictions\n",
    "        out = self(images)\n",
    "        # Get loss\n",
    "        loss = F.cross_entropy(out, labels)\n",
    "        return loss\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def validation_step(self, batch):\n",
    "        images, labels = batch\n",
    "        # Get predictions\n",
    "        out = self(images)\n",
    "        # Get loss\n",
    "        loss = F.cross_entropy(out, labels)\n",
    "        # Get accuracy\n",
    "        _, preds = torch.max(out, dim=1)\n",
    "        acc = accuracy_score(labels.cpu(), preds.cpu())\n",
    "        return {'val_loss': loss, 'val_acc': acc}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b207c2f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 20\n",
    "accs = []\n",
    "f1s = []\n",
    "for i in range(n):\n",
    "    model = SmallCNN()\n",
    "    criterion = CrossEntropyLoss()\n",
    "    optimizer = Adam(model.parameters(), lr=0.001)\n",
    "    epochs = 50\n",
    "    model = train_model(model, criterion, optimizer, dataloaders, image_datasets, 4, num_epochs=epochs)\n",
    "    acc, f1 = test(model, test_dataset)\n",
    "    accs.append(acc)\n",
    "    f1s.append(f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92b404f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "a, f = test(model, test_dataset)\n",
    "print(f\"Accuracy mean: {np.mean(accs)} std: {np.std(accs)}\")\n",
    "print(f\"F1 mean: {np.mean(f1s)} std: {np.std(f1s)}\")\n",
    "print(f\"Score of saved model: acc = {a} and f1 = {f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43c6458b",
   "metadata": {},
   "source": [
    "```\n",
    "Accuracy mean: 0.7074999999999999 std: 0.057608593109014575\n",
    "F1 mean: 0.7094406762827815 std: 0.06790884228169164\n",
    "Score of saved model: acc = 0.7 and f1 = 0.6666666666666666\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72c95e66",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test = [i for i,j in test_dataset]\n",
    "y_test = [j for i,j in test_dataset]\n",
    "preds = []\n",
    "outs = []\n",
    "for t in x_test:\n",
    "    pred, out = predict(model, t)\n",
    "    preds.append(pred)\n",
    "    \n",
    "print(f\"Accuracy: {accuracy_score(preds,y_test)}\")\n",
    "print(f\"F1 score: {f1_score(preds,y_test)}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "BrainMRI",
   "language": "python",
   "name": "brainmri"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
