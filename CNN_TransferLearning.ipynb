{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6384fa6b",
   "metadata": {},
   "source": [
    "# Task 3: Advanced CNN and TransferLearning\n",
    "\n",
    "\n",
    "We train a CNN, based on a larger [dataset](https://www.kaggle.com/datasets/ahmedhamada0/brain-tumor-detection?select=no) with 3k brain MRI images. Then we further finetune the model based on our original dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7980b673",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import numpy as np\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import accuracy_score, f1_score, plot_confusion_matrix, confusion_matrix, ConfusionMatrixDisplay\n",
    "\n",
    "import torch\n",
    "from torchvision import datasets, models, transforms\n",
    "import torch.nn as nn\n",
    "from torch.nn import functional as F\n",
    "from torch.nn import CrossEntropyLoss\n",
    "from torch.optim import Adam, SGD, RMSprop, lr_scheduler\n",
    "from torch.utils.data import TensorDataset, DataLoader, ConcatDataset\n",
    "\n",
    "import shap\n",
    "\n",
    "from data import get_img_dataset\n",
    "from project3Lib.transforms import EnhanceContrast\n",
    "import project3Lib.CNN as cnn\n",
    "from project3Lib.CNN import train_model, test, predict\n",
    "import project3Lib.utils as utils\n",
    "\n",
    "from masked_dataset import MaskedDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e7f0572",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Import TransferLearning Dataset\n",
    "transferlearning_path = \"data/tl_dataset\"\n",
    "transform = [EnhanceContrast(reduce_dim=False), transforms.Grayscale()]\n",
    "tl_train_dataset,tl_val_dataset, tl_test_dataset = get_img_dataset(transform, data_path=transferlearning_path, use_same_transforms = True)\n",
    "device = 'cuda:0' if torch.cuda.is_available() else 'cpu'\n",
    "print('Device state:', device)\n",
    "batch_size = 64\n",
    "tl_trainloader = DataLoader(tl_train_dataset, batch_size=batch_size, shuffle=True)\n",
    "tl_testloader = DataLoader(tl_test_dataset, batch_size=batch_size, shuffle=False)\n",
    "tl_validloader = DataLoader(tl_val_dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "dataloaders = {\n",
    "    'train' : tl_trainloader, \n",
    "    'validation': tl_validloader\n",
    "}\n",
    "\n",
    "image_datasets = {\n",
    "    'train': tl_train_dataset,\n",
    "    'validation': tl_val_dataset\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23652011",
   "metadata": {},
   "source": [
    "# Model implementation\n",
    "## 1. Train model on large dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1269a947",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = cnn.CNN()\n",
    "criterion = CrossEntropyLoss()\n",
    "optimizer = Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "epochs = 30\n",
    "model = train_model(model, criterion, optimizer, dataloaders, image_datasets, num_epochs=epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "989d0f86",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), f\"trained_weights/TL_basemodel.pt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30c417d8",
   "metadata": {},
   "source": [
    "**Evaluate base model and SHAP** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7aa1203b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = cnn.CNN()\n",
    "model.load_state_dict(torch.load(\"trained_weights/TL_basemodel.pt\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f162923",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Deep Explainer\n",
    "np.random.seed(123)\n",
    "indices = np.random.randint(0, high=len(tl_train_dataset), size=100)\n",
    "bg = torch.utils.data.Subset(tl_train_dataset, indices)\n",
    "bg = [i for i,j in bg]\n",
    "bg = torch.stack(bg)\n",
    "\n",
    "e = shap.DeepExplainer(model, bg)\n",
    "\n",
    "outs = []\n",
    "for i in bg:\n",
    "    pred, out = predict(model,i)\n",
    "    outs.append((out[0][0].item(), out[0][1].item()))\n",
    "print(f\"Mean values {np.mean([i for i,j in outs])}, {np.mean([j for i,j in outs])}\")\n",
    "\n",
    "\n",
    "indices = np.random.randint(0, high=len(tl_test_dataset), size=10)\n",
    "sub_test = torch.utils.data.Subset(tl_test_dataset, indices)\n",
    "\n",
    "test_images = [i for i,j in sub_test]\n",
    "y_test = [j for i,j in sub_test]\n",
    "\n",
    "for i, image in enumerate(test_images):\n",
    "    \n",
    "    image = image.reshape((1,1,128,128))\n",
    "    pred, out = predict(model,image)\n",
    "    shap_values = e.shap_values(image)\n",
    "    shap_numpy = [np.swapaxes(np.swapaxes(s, 1, -1), 1, 2) for s in shap_values]\n",
    "    test_numpy = np.swapaxes(np.swapaxes(image.cpu().numpy(), 1, -1), 1, 2)\n",
    "    print(f\"Image #{i}: True Class {y_test[i]}, Prediction {pred}, Probabilities {out}\")\n",
    "    shap.image_plot(shap_numpy, test_numpy, labels = [\"no\",\"yes\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48fe79f3",
   "metadata": {},
   "source": [
    "## 2. Transfer: finetune model on original dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ed3d2ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load and augment original data\n",
    "unique = input(\"Use unique images?[yes/no]\").lower() == \"yes\"\n",
    "input_path = \"data/unique_images\" if unique else \"data/images\"\n",
    "\n",
    "transform = [EnhanceContrast(reduce_dim=False), transforms.Grayscale()]\n",
    "train_dataset,val_dataset, test_dataset = get_img_dataset(transform, data_path=input_path, use_same_transforms = True)\n",
    "\n",
    "device = 'cuda:0' if torch.cuda.is_available() else 'cpu'\n",
    "print('Device state:', device)\n",
    "batch_size = 16\n",
    "trainloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "testloader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "validloader = DataLoader(val_dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "dataloaders = {\n",
    "    'train' : trainloader, \n",
    "    'validation': validloader\n",
    "}\n",
    "\n",
    "image_datasets = {\n",
    "    'train': train_dataset,\n",
    "    'validation': val_dataset\n",
    "}\n",
    "\n",
    "full_retrain = input(\"Retrain all layers? [yes/no]\").lower() == \"yes\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1fff273",
   "metadata": {},
   "outputs": [],
   "source": [
    "transfer_model = cnn.CNN()\n",
    "transfer_model.load_state_dict(torch.load(\"trained_weights/TL_basemodel.pt\"))\n",
    "if not full_retrain:\n",
    "    for param in transfer_model.parameters():\n",
    "        param.requires_grad = False\n",
    "    for layer in transfer_model.modules():\n",
    "        if isinstance(layer, nn.Linear):\n",
    "            layer.weight.requires_grad = True\n",
    "\n",
    "total_trainable_params = sum(\n",
    "    p.numel() for p in transfer_model.parameters() if p.requires_grad)\n",
    "print(f'{total_trainable_params:,} training parameters.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c652d9a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = CrossEntropyLoss()\n",
    "optimizer = Adam(transfer_model.parameters(), lr=0.0005)\n",
    "epochs = 20\n",
    "transfer_model = train_model(transfer_model, criterion, optimizer, dataloaders, image_datasets, num_epochs=epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef3d67f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(transfer_model.state_dict(), f\"trained_weights/TL_model.pt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e46a6d06",
   "metadata": {},
   "source": [
    "# Evaluate final Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "388b7a71",
   "metadata": {},
   "outputs": [],
   "source": [
    "transfer_model = cnn.CNN()\n",
    "transfer_model.load_state_dict(torch.load(\"trained_weights/TL_model.pt\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b6fb1c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test = [i for i,j in test_dataset]\n",
    "y_test = [j for i,j in test_dataset]\n",
    "preds = []\n",
    "outs = []\n",
    "for t in x_test:\n",
    "    pred, out = predict(transfer_model, t)\n",
    "    preds.append(pred)\n",
    "    \n",
    "print(f\"Accuracy: {accuracy_score(preds,y_test)}\")\n",
    "print(f\"F1 score: {f1_score(preds,y_test)}\")\n",
    "\n",
    "cm=confusion_matrix(y_test,preds,normalize=\"true\")\n",
    "cmd = ConfusionMatrixDisplay(cm)\n",
    "cmd.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "284ff936",
   "metadata": {},
   "source": [
    "```\n",
    "Accuracy: 0.95\n",
    "F1 score: 0.9565217391304348\n",
    "```\n",
    "\n",
    "![](Plots/CM_CNN_TL.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8822a3d1",
   "metadata": {},
   "source": [
    "# Interpretability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e12bdc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset_nomasks = test_dataset\n",
    "transform = [transforms.Grayscale()]\n",
    "common_transform = [EnhanceContrast(reduce_dim=False)]\n",
    "_,_, test_dataset = get_img_dataset(transform = transform, \\\n",
    "                                    use_same_transforms=True, \\\n",
    "                                    common_transforms=common_transform, \\\n",
    "                                    data_path=input_path, \\\n",
    "                                    folder_type = MaskedDataset, \\\n",
    "                                    mask_folder=Path(\"data/masks\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39a2ad4d",
   "metadata": {},
   "source": [
    "## SHAP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2509c90b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Deep Explainer\n",
    "bg = [i for i,j in train_dataset]\n",
    "bg = torch.stack(bg)\n",
    "e = shap.DeepExplainer(transfer_model, bg)\n",
    "outs = []\n",
    "for i in bg:\n",
    "    pred, out = predict(transfer_model,i)\n",
    "    outs.append((out[0][0].item(), out[0][1].item()))\n",
    "print(f\"Mean values {np.mean([i for i,j in outs])}, {np.mean([j for i,j in outs])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbc4ee08",
   "metadata": {},
   "outputs": [],
   "source": [
    "ious = []\n",
    "for i, (image,mask,target) in enumerate(test_dataset):\n",
    "    image = image.reshape((1,1,128,128))\n",
    "    pred, out = predict(transfer_model,image)\n",
    "    \n",
    "    shap_values = e.shap_values(image)\n",
    "    shap_numpy = [np.swapaxes(np.swapaxes(s, 1, -1), 1, 2) for s in shap_values]\n",
    "    test_numpy = np.swapaxes(np.swapaxes(image.cpu().numpy(), 1, -1), 1, 2)\n",
    "    print(f\"Image #{i}: True Class {target}, Prediction {pred}, Probabilities {out}\")\n",
    "    shap.image_plot(shap_numpy, test_numpy)\n",
    "    \n",
    "    predicted_mask = np.copy(shap_values[1].reshape(128,128))\n",
    "    mask = mask.numpy().reshape((128,128))\n",
    "    pixels = int(np.sum(mask.flatten()))\n",
    "    iou = utils.evaluate_interpretability(predicted_mask, mask,pixels)\n",
    "    print(iou)\n",
    "    if target == 1:\n",
    "        ious.append(iou)\n",
    "    if i == 0:\n",
    "        np.save(\"Plots/CNN_TL_SHAP_0\", predicted_mask)\n",
    "    if i == 0:\n",
    "        np.save(\"Plots/CNN_TL_SHAP_0\", predicted_mask)\n",
    "    \n",
    "print(f\"Mean IOU: {np.mean(ious)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a20257fa",
   "metadata": {},
   "source": [
    "```\n",
    "Mean IOU: 0.22387248291302617\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1ac97e6",
   "metadata": {},
   "source": [
    "# Integrated Gradients with Captum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d424b32f",
   "metadata": {},
   "outputs": [],
   "source": [
    "ious = []\n",
    "for i, (image,mask,target) in enumerate(test_dataset):\n",
    "    data = (image,target)\n",
    "    if target == 1: \n",
    "        class_1, class_0 = utils.plot_grads(data,transfer_model, layer_idx = -1,plot=False,grad_type= \"integ_grads\")\n",
    "    else:\n",
    "        class_0, class_1 = utils.plot_grads(data,transfer_model, layer_idx = -1,plot=False,grad_type= \"integ_grads\")\n",
    "    predicted_mask = np.copy(class_1.reshape(128,128))\n",
    "    mask = mask.numpy().reshape((128,128))\n",
    "    pixels = int(np.sum(mask.flatten()))\n",
    "    iou = utils.evaluate_interpretability(predicted_mask, mask,pixels)\n",
    "    if target == 1:\n",
    "        ious.append(iou)\n",
    "    if i == 0:\n",
    "        np.save(\"Plots/CNN_TL_IntGrad_0\", predicted_mask)\n",
    "    if i == 1:\n",
    "        np.save(\"Plots/CNN_TL_IntGrad_1\", predicted_mask)\n",
    "print(f\"The mean iou is {np.mean(ious)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "730fcd45",
   "metadata": {},
   "source": [
    "The mean iou is 0.15528650486299014"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddd90236",
   "metadata": {},
   "outputs": [],
   "source": [
    "utils.plot_grads_dataloader(test_dataset_nomasks, transfer_model, grad_type= \"integ_grads\" ,plot=True, save_name=\"tl_cnn\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7dde466a",
   "metadata": {},
   "source": [
    "# GradCam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46b4aab0",
   "metadata": {},
   "outputs": [],
   "source": [
    "ious = []\n",
    "for i, (image,mask, target) in enumerate(test_dataset):\n",
    "    data = (image,target)\n",
    "    if target == 1: \n",
    "        class_1, class_0 = utils.plot_grads(data,transfer_model, layer_idx = 4,plot=False,grad_type= \"grad_cam\")\n",
    "    else:\n",
    "        class_0, class_1 = utils.plot_grads(data,transfer_model, layer_idx = 4,plot=False,grad_type= \"grad_cam\")\n",
    "    \n",
    "    predicted_mask = np.copy(class_1.detach().numpy().reshape(128,128))\n",
    "    mask = mask.numpy().reshape((128,128))\n",
    "    pixels = int(np.sum(mask.flatten()))\n",
    "    iou = utils.evaluate_interpretability(predicted_mask, mask,pixels)\n",
    "    if target == 1:\n",
    "        ious.append(iou)\n",
    "    if i == 0:\n",
    "        np.save(f\"Plots/CNN_TL_GradCam_0\", predicted_mask)\n",
    "    if i == 1:\n",
    "        np.save(f\"Plots/CNN_TL_GradCam_1\", predicted_mask)\n",
    "print(f\"The mean iou is {np.mean(ious)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bf400a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "utils.plot_grads_dataloader(test_dataset_nomasks, transfer_model, grad_type= \"grad_cam\" ,plot=True,layer_idx=4, save_name=\"tl_cnn\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "BrainMRI",
   "language": "python",
   "name": "brainmri"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
